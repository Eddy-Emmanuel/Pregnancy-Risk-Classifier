{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c3c1c8-f177-4875-b464-4fe9cbfe4ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(action=\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a9d328-89b0-424c-91a5-891fe7b91343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1582, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATERNAL AGE</th>\n",
       "      <th>GESTATIONAL AGE</th>\n",
       "      <th>PARITY</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>BMI</th>\n",
       "      <th>SYSTOLIC BP</th>\n",
       "      <th>DIASTOLIC BP</th>\n",
       "      <th>URINE ANALYSIS</th>\n",
       "      <th>RISK LEVEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>22.913033</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>29.319856</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>33.057851</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>32.223416</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>30.091432</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>Mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MATERNAL AGE  GESTATIONAL AGE  PARITY  WEIGHT HEIGHT        BMI  \\\n",
       "0            25             41.0       0    67.0   1.71  22.913033   \n",
       "1            31             21.0       0    76.0   1.61  29.319856   \n",
       "2            40             16.0       0    90.0   1.65  33.057851   \n",
       "3            30             19.0       0    57.0   1.33  32.223416   \n",
       "4            33             25.0       3    78.0   1.61  30.091432   \n",
       "\n",
       "  SYSTOLIC BP  DIASTOLIC BP URINE ANALYSIS RISK LEVEL  \n",
       "0         180            90       NEGATIVE       High  \n",
       "1         130            80       NEGATIVE        Mid  \n",
       "2         140            90       NEGATIVE       High  \n",
       "3         130            80       NEGATIVE        Mid  \n",
       "4         120            60       NEGATIVE        Mid  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"Compiled Maternal Data.xlsx\",sheet_name = 'Sheet2')\n",
    "\n",
    "print(\"Shape: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e176e1-e159-4901-b313-6b5925c3d7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([392], dtype='int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_rows = df[df['HEIGHT'] == '166/158'].index\n",
    "df.drop(bad_rows, inplace=True)\n",
    "bad_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21eac2f8-d837-45ae-a1cf-5fb854cef08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['SYSTOLIC BP'] == '1o5', 'SYSTOLIC BP'] = '105'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ad6458-07dc-4e3b-9aaf-6c21a7465be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HEIGHT'] = pd.to_numeric(df['HEIGHT'], errors='coerce')\n",
    "df['SYSTOLIC BP'] = pd.to_numeric(df['SYSTOLIC BP'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90042278-bdd8-4d77-9fa0-80f5c86551ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RISK LEVEL'] = df['RISK LEVEL'].map(lambda x: x if x in ['Low', 'High'] else 'Mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89fc2f9a-c9a2-49e2-add6-dd816b278338",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NON NEGATIVE URINE ANALYSIS'] = df['URINE ANALYSIS'].apply(lambda x: 0 if x == 'NEGATIVE' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7335d62f-f101-4d73-ae78-728214931b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "urine_map = {\n",
    "    'NEGATIVE': 0,\n",
    "    'POSITIVE': 1,\n",
    "    'GLUCOSE TRACE': 2\n",
    "}\n",
    "\n",
    "df['URINE ANALYSIS'] = df['URINE ANALYSIS'].map(urine_map).fillna(3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690522db-1c05-4580-8e4b-d0ff7cb9a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_level_map = {\n",
    "    'High': 0,\n",
    "    'Mid': 1,\n",
    "    'Low': 2\n",
    "}\n",
    "\n",
    "df['RISK LEVEL'] = df['RISK LEVEL'].map(risk_level_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ca621c-bc92-4652-9099-d394ae8e9087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MATERNAL AGE                   0\n",
       "GESTATIONAL AGE                3\n",
       "PARITY                         0\n",
       "WEIGHT                         2\n",
       "HEIGHT                         0\n",
       "BMI                            0\n",
       "SYSTOLIC BP                    0\n",
       "DIASTOLIC BP                   0\n",
       "URINE ANALYSIS                 0\n",
       "RISK LEVEL                     0\n",
       "NON NEGATIVE URINE ANALYSIS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9560ffe3-a649-4e73-b6c4-177f172427e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "867e60e6-ac95-4854-aa81-619a123cfbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df, threshold=1.5):\n",
    "    outliers = {}\n",
    "    for column in df.select_dtypes(include='number').columns:\n",
    "        q1 = df[column].quantile(0.25)\n",
    "        q3 = df[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - threshold * iqr\n",
    "        upper_bound = q3 + threshold * iqr\n",
    "\n",
    "        outlier_values = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
    "        if not outlier_values.empty:\n",
    "            outliers[column] = outlier_values\n",
    "\n",
    "    return outliers\n",
    "\n",
    "outliers = detect_outliers_iqr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03bef809-f145-42f7-adb0-bcd5ce1f84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop(\"RISK LEVEL\")\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b949ac08-8ad3-461a-9b9d-a1d9d52e83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Algorithms(X, y, algorithms):\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    test_metrics = {\"F1_SCORE\": [], \"PRECISION\": [], \"RECALL\": [], \"ACCURACY\": []}\n",
    "    train_metrics = {\"F1_SCORE\": [], \"PRECISION\": [], \"RECALL\": [], \"ACCURACY\": []}\n",
    "    \n",
    "    model_names, predictions, probabilities = [], [], []\n",
    "    trained_models = {}\n",
    "\n",
    "    for algo in algorithms:\n",
    "        # Smart initialization based on model name\n",
    "        if algo.__name__ == \"CatBoostClassifier\":\n",
    "            model = algo(silent=True)\n",
    "        elif algo.__name__ == \"XGBClassifier\":\n",
    "            model = algo(verbose=False)\n",
    "        elif algo.__name__ == \"LGBMClassifier\":\n",
    "            model = algo(verbosity=-1)\n",
    "        elif algo.__name__ == \"SVC\":\n",
    "            model = algo(probability=True)\n",
    "        else:\n",
    "            model = algo()\n",
    "\n",
    "        fold_metrics_test = {\"F1\": [], \"PRECISION\": [], \"RECALL\": [], \"ACCURACY\": []}\n",
    "        fold_metrics_train = {\"F1\": [], \"PRECISION\": [], \"RECALL\": [], \"ACCURACY\": []}\n",
    "\n",
    "        for train_idx, test_idx in tqdm(skf.split(X, y), desc=f\"{algo.__name__}\", total=skf.get_n_splits()):\n",
    "            x_train, x_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            y_pred_test = model.predict(x_test)\n",
    "            y_pred_train = model.predict(x_train)\n",
    "\n",
    "            # Test metrics\n",
    "            fold_metrics_test[\"F1\"].append(metrics.f1_score(y_test, y_pred_test, average=\"macro\"))\n",
    "            fold_metrics_test[\"PRECISION\"].append(metrics.precision_score(y_test, y_pred_test, average=\"macro\"))\n",
    "            fold_metrics_test[\"RECALL\"].append(metrics.recall_score(y_test, y_pred_test, average=\"macro\"))\n",
    "            fold_metrics_test[\"ACCURACY\"].append(metrics.accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "            # Train metrics\n",
    "            fold_metrics_train[\"F1\"].append(metrics.f1_score(y_train, y_pred_train, average=\"macro\"))\n",
    "            fold_metrics_train[\"PRECISION\"].append(metrics.precision_score(y_train, y_pred_train, average=\"macro\"))\n",
    "            fold_metrics_train[\"RECALL\"].append(metrics.recall_score(y_train, y_pred_train, average=\"macro\"))\n",
    "            fold_metrics_train[\"ACCURACY\"].append(metrics.accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "        # Store final metrics\n",
    "        model_name = algo.__name__\n",
    "        model_names.append(model_name)\n",
    "        test_metrics[\"F1_SCORE\"].append(np.mean(fold_metrics_test[\"F1\"]))\n",
    "        test_metrics[\"PRECISION\"].append(np.mean(fold_metrics_test[\"PRECISION\"]))\n",
    "        test_metrics[\"RECALL\"].append(np.mean(fold_metrics_test[\"RECALL\"]))\n",
    "        test_metrics[\"ACCURACY\"].append(np.mean(fold_metrics_test[\"ACCURACY\"]))\n",
    "\n",
    "        train_metrics[\"F1_SCORE\"].append(np.mean(fold_metrics_train[\"F1\"]))\n",
    "        train_metrics[\"PRECISION\"].append(np.mean(fold_metrics_train[\"PRECISION\"]))\n",
    "        train_metrics[\"RECALL\"].append(np.mean(fold_metrics_train[\"RECALL\"]))\n",
    "        train_metrics[\"ACCURACY\"].append(np.mean(fold_metrics_train[\"ACCURACY\"]))\n",
    "\n",
    "        # Store predictions and trained model\n",
    "        predictions.append(model.predict(X))\n",
    "        probabilities.append(model.predict_proba(X)[:, 0])  # first class probability\n",
    "        trained_models[model_name] = model\n",
    "\n",
    "    # Tabulated metric summaries\n",
    "    test_table = tabulate(pd.DataFrame(test_metrics).T, headers=[name.replace(\"Classifier\", \"\") for name in model_names], tablefmt=\"double_grid\")\n",
    "    train_table = tabulate(pd.DataFrame(train_metrics).T, headers=[name.replace(\"Classifier\", \"\") for name in model_names], tablefmt=\"double_grid\")\n",
    "\n",
    "    # Helper to format predictions/probabilities\n",
    "    def format_output(output_list):\n",
    "        df_output = pd.DataFrame(output_list).T\n",
    "        df_output.columns = model_names\n",
    "        return df_output\n",
    "\n",
    "    return test_table, train_table, format_output(predictions), format_output(probabilities), trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c048a5e0-1744-4f36-9ca9-620a000c3281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: 100%|██████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 10.26it/s]\n",
      "RandomForestClassifier: 100%|██████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "GradientBoostingClassifier: 100%|██████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.10s/it]\n",
      "XGBClassifier: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.53it/s]\n",
      "LGBMClassifier: 100%|██████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.16it/s]\n",
      "CatBoostClassifier: 100%|██████████████████████████████████████████████████████████████| 10/10 [01:06<00:00,  6.66s/it]\n"
     ]
    }
   ],
   "source": [
    "data_test, data_train, pred, pred_proba, trained_models = Train_Algorithms(X, y, \n",
    "                                                                           [DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier, \n",
    "                                                                            XGBClassifier, LGBMClassifier,  CatBoostClassifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d10cff62-7595-4ebf-920f-eb8a18c2e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═══════════╦════════════════╦════════════════╦════════════════════╦═══════╦════════╦════════════╗\n",
      "║           ║   DecisionTree ║   RandomForest ║   GradientBoosting ║   XGB ║   LGBM ║   CatBoost ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬═══════╬════════╬════════════╣\n",
      "║ F1_SCORE  ║              1 ║              1 ║           0.945734 ║     1 ║      1 ║   0.999217 ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬═══════╬════════╬════════════╣\n",
      "║ PRECISION ║              1 ║              1 ║           0.9573   ║     1 ║      1 ║   0.999363 ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬═══════╬════════╬════════════╣\n",
      "║ RECALL    ║              1 ║              1 ║           0.935501 ║     1 ║      1 ║   0.999073 ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬═══════╬════════╬════════════╣\n",
      "║ ACCURACY  ║              1 ║              1 ║           0.954249 ║     1 ║      1 ║   0.999016 ║\n",
      "╚═══════════╩════════════════╩════════════════╩════════════════════╩═══════╩════════╩════════════╝\n"
     ]
    }
   ],
   "source": [
    "print(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6602ae51-4745-4b3f-a071-61c37490d011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═══════════╦════════════════╦════════════════╦════════════════════╦══════════╦══════════╦════════════╗\n",
      "║           ║   DecisionTree ║   RandomForest ║   GradientBoosting ║      XGB ║     LGBM ║   CatBoost ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬══════════╬══════════╬════════════╣\n",
      "║ F1_SCORE  ║       0.788408 ║       0.847685 ║           0.854265 ║ 0.836265 ║ 0.836431 ║   0.839017 ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬══════════╬══════════╬════════════╣\n",
      "║ PRECISION ║       0.79694  ║       0.872401 ║           0.873261 ║ 0.856956 ║ 0.862245 ║   0.861606 ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬══════════╬══════════╬════════════╣\n",
      "║ RECALL    ║       0.790064 ║       0.83948  ║           0.847898 ║ 0.830764 ║ 0.828435 ║   0.83263  ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬══════════╬══════════╬════════════╣\n",
      "║ ACCURACY  ║       0.830523 ║       0.889977 ║           0.895665 ║ 0.876073 ║ 0.881745 ║   0.884273 ║\n",
      "╚═══════════╩════════════════╩════════════════╩════════════════════╩══════════╩══════════╩════════════╝\n"
     ]
    }
   ],
   "source": [
    "print(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "586c1ecd-56d5-41ed-815d-f0554c54c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def Train_Algorithms_and_Upsample_Minority_class(X, y, algo):\n",
    "    # Print value counts of the original dataset\n",
    "    print(\"Original Target Distribution:\")\n",
    "    print(y.value_counts().to_string())\n",
    "    print()\n",
    "\n",
    "    # Perform upsampling\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "    # Print value counts after upsampling\n",
    "    print(\"After Upsampling Target Distribution:\")\n",
    "    print(y_resampled.value_counts().to_string())\n",
    "    print()\n",
    "\n",
    "    # Initialize Stratified K-Fold\n",
    "    stf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "    # Initialize dictionaries and lists\n",
    "    model_performance = {\"F1_SCORE\": [], \"PRECISION\": [], \"RECALL\": [], \"ACCURACY\": []}\n",
    "    model_performances = {\"F1_SCORE\": [], \"PRECISION\": [], \"RECALL\": [], \"ACCURACY\": []}\n",
    "    model_names, pred, pred_proba = [], [], []\n",
    "    trained_models = {}\n",
    "\n",
    "    for algorithms in algo:\n",
    "        init_algo = algorithms(silent=True) if algorithms.__name__ == \"CatBoostClassifier\"\\\n",
    "                    else algorithms(verbose=False) if algorithms.__name__ == \"XGBClassifier\"\\\n",
    "                    else algorithms(verbosity=-1) if algorithms.__name__ == \"LGBMClassifier\"\\\n",
    "                    else algorithms(probability=True) if algorithms.__name__ == \"SVC\"\\\n",
    "                    else algorithms()\n",
    "\n",
    "        F1_SCORE, F1_SCORE_TRAIN = [], []\n",
    "        PRECISION, PRECISION_TRAIN = [], []\n",
    "        RECALL, RECALL_TRAIN = [], []\n",
    "        ACCURACY, ACCURACY_TRAIN = [], []\n",
    "\n",
    "        # Split the upsampled dataset\n",
    "        for train_idx, test_idx in tqdm(stf.split(X_resampled, y_resampled), desc=f\"{algorithms.__name__}\", total=len(algo)):\n",
    "            xtrain, xtest = X_resampled.iloc[train_idx], X_resampled.iloc[test_idx]\n",
    "            ytrain, ytest = y_resampled.iloc[train_idx], y_resampled.iloc[test_idx]\n",
    "\n",
    "            # Fit the model\n",
    "            init_algo.fit(xtrain, ytrain)\n",
    "            test_pred = init_algo.predict(xtest)\n",
    "            train_pred = init_algo.predict(xtrain)\n",
    "\n",
    "            # Test Metrics\n",
    "            F1_SCORE.append(metrics.f1_score(y_true=ytest, y_pred=test_pred, average=\"macro\"))\n",
    "            PRECISION.append(metrics.precision_score(y_true=ytest, y_pred=test_pred, average=\"macro\"))\n",
    "            RECALL.append(metrics.recall_score(y_true=ytest, y_pred=test_pred, average=\"macro\"))\n",
    "            ACCURACY.append(metrics.accuracy_score(y_true=ytest, y_pred=test_pred))\n",
    "\n",
    "            # Train Metrics\n",
    "            F1_SCORE_TRAIN.append(metrics.f1_score(y_true=ytrain, y_pred=train_pred, average=\"macro\"))\n",
    "            PRECISION_TRAIN.append(metrics.precision_score(y_true=ytrain, y_pred=train_pred, average=\"macro\"))\n",
    "            RECALL_TRAIN.append(metrics.recall_score(y_true=ytrain, y_pred=train_pred, average=\"macro\"))\n",
    "            ACCURACY_TRAIN.append(metrics.accuracy_score(y_true=ytrain, y_pred=train_pred))\n",
    "\n",
    "        # Store predictions\n",
    "        pred_proba.append(init_algo.predict_proba(X_resampled)[:, 0])  # take the first data probability\n",
    "        pred.append(init_algo.predict(X_resampled))  # take predicted score\n",
    "\n",
    "        # Append model names and performance metrics\n",
    "        model_names.append(algorithms.__name__)\n",
    "        model_performance[\"F1_SCORE\"].append(np.mean(F1_SCORE))\n",
    "        model_performance[\"PRECISION\"].append(np.mean(PRECISION))\n",
    "        model_performance[\"RECALL\"].append(np.mean(RECALL))\n",
    "        model_performance[\"ACCURACY\"].append(np.mean(ACCURACY))\n",
    "\n",
    "        # Train Model Performance\n",
    "        model_performances[\"F1_SCORE\"].append(np.mean(F1_SCORE_TRAIN))\n",
    "        model_performances[\"PRECISION\"].append(np.mean(PRECISION_TRAIN))\n",
    "        model_performances[\"RECALL\"].append(np.mean(RECALL_TRAIN))\n",
    "        model_performances[\"ACCURACY\"].append(np.mean(ACCURACY_TRAIN))\n",
    "\n",
    "        trained_models[algorithms.__name__] = init_algo\n",
    "\n",
    "    # Format performance results into tables\n",
    "    data_train = tabulate(pd.DataFrame(model_performances).T, headers=[i.split(\"Classifier\")[0] for i in model_names], tablefmt=\"double_grid\")\n",
    "    data = tabulate(pd.DataFrame(model_performance).T, headers=[i.split(\"Classifier\")[0] for i in model_names], tablefmt=\"double_grid\")\n",
    "\n",
    "    # Helper function to clean predictions for CSV output\n",
    "    def clean_csv(df):\n",
    "        df_fix = pd.DataFrame(pd.DataFrame(df).T)\n",
    "        column_names = df_fix.columns.tolist()\n",
    "        for old_col, new_col in zip(column_names, model_names):\n",
    "            df_fix.rename(columns={old_col: new_col}, inplace=True)\n",
    "        return df_fix\n",
    "\n",
    "    return data, data_train, clean_csv(pred), clean_csv(pred_proba), y_resampled, trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcbfce51-c824-4006-9366-2206aa722994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Target Distribution:\n",
      "RISK LEVEL\n",
      "2    844\n",
      "1    545\n",
      "0    192\n",
      "\n",
      "After Upsampling Target Distribution:\n",
      "RISK LEVEL\n",
      "0    844\n",
      "1    844\n",
      "2    844\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: 10it [00:00, 32.69it/s]                                                                        \n"
     ]
    }
   ],
   "source": [
    "data_upsample, data_train_upsample, pred_upsample, pred_proba_upsample, y_upsample, trained_models = Train_Algorithms_and_Upsample_Minority_class(X, y,\n",
    "                                                                                                                                                  [DecisionTreeClassifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea64159d-66b2-4977-8506-590fb59e1936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═══════════╦════════════════╗\n",
      "║           ║   DecisionTree ║\n",
      "╠═══════════╬════════════════╣\n",
      "║ F1_SCORE  ║              1 ║\n",
      "╠═══════════╬════════════════╣\n",
      "║ PRECISION ║              1 ║\n",
      "╠═══════════╬════════════════╣\n",
      "║ RECALL    ║              1 ║\n",
      "╠═══════════╬════════════════╣\n",
      "║ ACCURACY  ║              1 ║\n",
      "╚═══════════╩════════════════╝\n"
     ]
    }
   ],
   "source": [
    "# @title UPSAMPLING TRAINING PERFORMANCE RESULT\n",
    "print(data_train_upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a50c945a-0bff-478f-9b6a-473ce2b2211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═══════════╦════════════════╦════════════════╦════════════════════╦═══════╦════════╦════════════╗\n",
      "║           ║   DecisionTree ║   RandomForest ║   GradientBoosting ║   XGB ║   LGBM ║   CatBoost ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬═══════╬════════╬════════════╣\n",
      "║ F1_SCORE  ║              1 ║              1 ║           0.945734 ║     1 ║      1 ║   0.999217 ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬═══════╬════════╬════════════╣\n",
      "║ PRECISION ║              1 ║              1 ║           0.9573   ║     1 ║      1 ║   0.999363 ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬═══════╬════════╬════════════╣\n",
      "║ RECALL    ║              1 ║              1 ║           0.935501 ║     1 ║      1 ║   0.999073 ║\n",
      "╠═══════════╬════════════════╬════════════════╬════════════════════╬═══════╬════════╬════════════╣\n",
      "║ ACCURACY  ║              1 ║              1 ║           0.954249 ║     1 ║      1 ║   0.999016 ║\n",
      "╚═══════════╩════════════════╩════════════════╩════════════════════╩═══════╩════════╩════════════╝\n"
     ]
    }
   ],
   "source": [
    "# @title UPSAMPLING PERFORMANCE RESULT\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7910b274-8e86-43be-8421-052a12ece251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═══════════╦════════════════╗\n",
      "║           ║   DecisionTree ║\n",
      "╠═══════════╬════════════════╣\n",
      "║ F1_SCORE  ║       0.937144 ║\n",
      "╠═══════════╬════════════════╣\n",
      "║ PRECISION ║       0.938628 ║\n",
      "╠═══════════╬════════════════╣\n",
      "║ RECALL    ║       0.937652 ║\n",
      "╠═══════════╬════════════════╣\n",
      "║ ACCURACY  ║       0.937643 ║\n",
      "╚═══════════╩════════════════╝\n"
     ]
    }
   ],
   "source": [
    "# @title UPSAMPLING TEST PERFORMANCE RESULT\n",
    "print(data_upsample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
